#include "services_microboone.fcl"

# A script to run an analysis module: MuCSReader. You may want to
# compare this script with ${LARSIM_DIR}/job/prodsingle.fcl; in
# particular, in this script there are no output streams because the
# module doesn't write any events, just histograms or n-tuples.

# See <https://cdcvs.fnal.gov/redmine/projects/larsoftsvn/wiki/Running_Jobs> for 
# more information on the structure of .fcl files. 

process_name: MuCSReader

services:
{
  # Load the service that manages root files for histograms.
  # Any histograms or n-tuples that you create in the program will be
  # written to this file. You can override the file name with the -T
  # option on the command line; e.g.,
  #  lar -c MuCSReader.fcl -T myhistograms.root -s myinput.root

  TFileService: { fileName: "/uboone/data/users/kalousis/MuCS/MuCSReader.root" }

  # This constrols the display in the output of how long each job step
  # takes for each event. The only parameter you can put in here is
  # "summaryOnly: true" if you want to suppress this output.

  Timing:       {}

  # ART native random number generator. Normally this is only needed
  # for simulations, but you never know.

  RandomNumberGenerator: {} 

  # This parameter controls the level of descriptive output from
  # various LArSoft modules. For a list of different message levels,
  # see ${LARDATA_DIR}/job/messageservice.fcl. For most jobs this is
  # set to standard_warning; here it is set to standard_info because I
  # write some LogInfo messages in the analysis module for
  # demonstration purposes.

  message:      @local::standard_info

  # This defines many default LArSoft resources for this job. It's
  # more than we'll need, but it's easier to include all of them than
  # to pick and choose. For a list of what's being defined, see
  # ${LARDATA_DIR}/job/services.fcl (which will lead you to other
  # files in the various products' job directories).

  user:         @local::microboone_simulation_services
}

# The 'source' section tells the script to expect an input file with art::Event records.
# Note that the name of the input file is not included here. You specify that on the
# command line when you run this script; e.g.,
#    lar -c MuCSReader.fcl -s myinput.root
# The file "myinput.root" is assumed to have been created by a previous LArSoft job.

source:
{
  module_type: RootInput

  # Number of events to analyze; "-1" means all of the events in the input
  # file. You can override this value with the "-n" option on the command line. 
  maxEvents: -1 

  # I've commented this out, but if you really want to include the name of
  # an input file in this script, here's how you do it.
  # fileNames: ["myinput.root"]
}

# This is empty, because we're not writing any art::Events to an output file. 
outputs:{}

# The 'physics' section defines and configures some modules to do work on each event.
# First modules are defined; they are scheduled later. Modules are grouped by type.
physics:
{
  # Define the variables we'll need to run for this analysis program.
  analyzers:
  {
    # This name defines a job step below, and will appear as a directory 
    # in the output histogram file. 
    MuCSReader: 
    {
      # The "module_type" tells us which module to run. The name here
      # matches the name supplied to DEFINE_ART_MODULE near the end of
      # MuCSReader_module.cc.

      module_type:     "MuCSReader"

      # The input parameters for our MuCSReader module. Compare
      # the names you see here with the reconfigure method in
      # MuCSReader.cxx. You will want to add/remove/rename the
      # example parameters below to suit your task.

      # If you are reading any objects created by the simulation, then
      # don't change the value of this parameter. This is the name of
      # the 'producer' that ran the simulation module in a previous
      # job. An example of a job file that runs the simulation is
      # ${LARSIM_DIR}/job/prodsingle.fcl; look for "largeant:". It's
      # unlikely that anyone would change the name of this producer.

      SimulationLabel: "largeant"

      # Hits can be created by more than one module in
      # ${LARRECO_DIR}/source/HitFinder. For this example, I picked
      # the one that's usually run first.
      
      HitLabel: "gaushit"

      # The same for clusters:

      ClusterLabel:    "fuzzycluster"

      # In this example, which primary particle(s) we'll focus on in an event.
      # PDG code 13 = mu-.
      PDGcode:          13

      # dx used for the dE/dx calculation; units are cm. 
      BinSize:          0.3
      			
      # Bezier tracker
             
      BezierRecoLabel: "trackkalmanhit" 
            
      OpFlashLabel: "opflash"
      
      MergerProducerLabel: "merger"
            
      }
  }

  # Schedule job step(s) for execution by defining the analysis module
  # for this job. An 'analysis' module (as opposed to a 'producer' or
  # a 'filter') does not alter the contents of events in the input
  # file, nor does it create any events as output. Any step names
  # listed here must match a name in the 'analyzers' section above.

  analysis: [ MuCSReader ]

  # "end_paths" is a keyword and contains the modules that do not modify the art::Event;
  # i.e., analyzers and output streams. 

  end_paths: [ analysis ]  
}

