#include "services_microboone.fcl"
#include "opticaldetectormodules_microboone.fcl"
#include "triggeralgo_service.fcl"

process_name: HGLGsaturation

services:
{
  scheduler:               { defaultExceptions: false }    # Make all uncaught exceptions fatal.
  # Load the service that manages root files for histograms.
  TFileService:            { fileName: "correct_saturation_hist.root" }
  Timing:                  {}
  SimpleMemoryCheck:       { ignoreTotal: 1 } # default is one
  RandomNumberGenerator:   {} #ART native random number generator
  message:                 @local::microboone_message_services_prod_debug
  FileCatalogMetadata:     @local::art_file_catalog_mc
  PhotonVisibilityService: @local::microboone_photonvisibilityservice
                           @table::microboone_services_reco
}

#source is now a root file
source:
{
  module_type: RootInput
  maxEvents:   -1        # Number of events to create
}

# Define and configure some modules to do work on each event.
# First modules are defined; they are scheduled later.
# Modules are grouped by type.
physics:
{

    producers:
 {

  ### random number saver
  rns:                 { module_type: RandomNumberSaver }

  ### flash finders
  saturation : { module_type : "OpDigitSaturationCorrection"  verbose : false CalibrationCorr : [1.014,1.024,1.013,1.003,1.014,0.993,1.004,0.957,0.939,0.981,0.918,0.960,0.953,0.937,1.005,0.964,1.059,1.328,1.399,1.373,1.307,1.294,1.357,1.325,1.292,1.356,1.468,1.299,1.385,1.314,1.320,1.365] }
 }
 analyzers:
 {
 }

 #reco: [ rns, opflash, simpleFlash, opflashfilter ]
 reco: [ rns, saturation ]
 ana: []

 #define the output stream, there could be more than one if using filters 
 stream1:  [ out1 ]

 #trigger_paths is a keyword and contains the paths that modify the art::event, 
 #ie filters and producers
 #trigger_paths: [reco] 

 #end_paths is a keyword and contains the paths that do not modify the art::Event, 
 #ie analyzers and output streams.  these all run simultaneously
 end_paths:     [stream1,ana]
}

#block to define where the output goes.  if you defined a filter in the physics
#block and put it in the trigger_paths then you need to put a SelectEvents: {SelectEvents: [XXX]}
#entry in the output stream you want those to go to, where XXX is the label of the filter module(s)
outputs:
{
 out1:
 {
   module_type: RootOutput
   fileName:    "saturation_wfs.root"
   dataTier:    "reconstructed-wfs"
   compressionLevel: 1
   outputCommands: ["keep *_*_*_*",
                    "drop raw::RawDigits_*_*_*",
                    "drop recob::Cluster_*_*_*",
                    "drop recob::EndPoint2D_*_*_*",
                    "drop recob::Hit_*_*_*",
                    "drop recob::Vertex_*_*_*",
                    "drop recob::Wires_*_*_*"]
 }
}

### Here we include the file giving us run/data dependent overrides

services.DatabaseUtil.ShouldConnect: false
services.IDetPedestalService.DetPedestalRetrievalAlg.UseDB: false

### Here we try to suppress known and pointless messages
services.message.destinations :
{
  STDCOUT: 
  {
     type:      "cout"      #tells the message service to output this destination to cout
     threshold: "WARNING"   #tells the message service that this destination applies to WARNING and higher level messages
     append:     true       #says to append all messages to the output
     categories:
     {
       ChannelFilter:
       {
         limit: 0
         reportEvery: 0
       }
       default:
       {
         limit: -1  #don't print anything at the infomsg level except the explicitly named categories
         reportEvery: 1
       }
     }
  }
}


